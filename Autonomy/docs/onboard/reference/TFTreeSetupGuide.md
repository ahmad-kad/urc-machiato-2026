# TF Tree Setup Guide - URC 2026 Rover

## Overview

The Transform (TF) tree is the backbone of coordinate frame management in ROS 2, enabling proper sensor fusion, localization, and control for the URC 2026 rover. This guide covers comprehensive TF tree configuration, static and dynamic transform publishing, and debugging procedures critical for accurate navigation and manipulation tasks.

## ðŸ“Š **Why TF Tree Setup Matters**

### **Mission Impact**
- **Navigation Accuracy**: TF enables coordinate transformations between GPS, IMU, LIDAR, and camera frames
- **Sensor Fusion**: Proper alignment of all sensor data for SLAM and localization
- **Autonomous Typing**: Accurate hand-eye calibration between camera and robotic arm
- **Object Detection**: Correct transformation of detected objects to robot coordinate frame

### **TF Tree Consequences**
```
Improper TF Setup â†’ Coordinate Mismatches â†’ Navigation Errors â†’ Mission Failure
```

- **Position Errors**: 0.5-2m errors in object localization
- **Orientation Errors**: 5-15Â° misalignment between sensors
- **Sensor Fusion Failures**: Inconsistent data preventing reliable localization
- **Arm Control Errors**: Incorrect positioning for autonomous typing

---

## ðŸ”§ **TF Tree Fundamentals**

### **Core Concepts**

#### **Coordinate Frames**
- **map**: Global reference frame (GPS coordinates)
- **odom**: Odometry reference frame (accumulated motion)
- **base_link**: Robot's base coordinate frame
- **Sensor frames**: Individual sensor coordinate frames (camera, lidar, imu)
- **End-effector frames**: Robotic arm coordinate frames

#### **Transform Types**
- **Static Transforms**: Fixed relationships (sensor mounting positions)
- **Dynamic Transforms**: Changing relationships (wheel odometry, arm joints)

### **ROS 2 TF2 Architecture**
```python
# TF2 core components
from tf2_ros import TransformBroadcaster, StaticTransformBroadcaster
from geometry_msgs.msg import TransformStamped
import tf2_geometry_msgs
```

---

## ðŸ“‹ **TF Tree Prerequisites**

### **Hardware Requirements**
- **Precise Measurements**: Accurate sensor mounting positions (Â±1mm)
- **Coordinate System**: Consistent right-hand rule convention
- **Mounting Stability**: Rigid sensor mounts without play

### **Software Requirements**
```bash
# Install TF2 tools
sudo apt install ros-humble-tf2-tools
sudo apt install ros-humble-tf2-ros
sudo apt install ros-humble-tf2-geometry-msgs

# Optional visualization
sudo apt install ros-humble-rviz2
```

### **URDF Integration**
```xml
<!-- Example sensor mounting in URDF -->
<joint name="camera_joint" type="fixed">
  <parent link="base_link"/>
  <child link="camera_link"/>
  <origin xyz="0.3 0 0.5" rpy="0 0.52 0"/> <!-- Measured mounting position -->
</joint>
```

---

## ðŸŒ³ **Complete TF Tree Structure**

### **URC 2026 TF Tree Hierarchy**

```
map (GPS/Global frame)
â”œâ”€â”€ odom (Odometry frame)
    â””â”€â”€ base_link (Robot base)
        â”œâ”€â”€ imu_link (IMU sensor)
        â”œâ”€â”€ lidar_link (2D LIDAR)
        â”œâ”€â”€ camera_link (RGB-D camera)
        â”‚   â”œâ”€â”€ camera_depth_frame
        â”‚   â””â”€â”€ camera_color_frame
        â”œâ”€â”€ gps_link (GPS receiver)
        â”œâ”€â”€ arm_base_link (Robotic arm base)
        â”‚   â”œâ”€â”€ arm_joint1
        â”‚   â”‚   â”œâ”€â”€ arm_joint2
        â”‚   â”‚   â”‚   â””â”€â”€ arm_end_effector
        â””â”€â”€ wheel_links (4 wheel assemblies)
            â”œâ”€â”€ front_left_wheel
            â”œâ”€â”€ front_right_wheel
            â”œâ”€â”€ rear_left_wheel
            â””â”€â”€ rear_right_wheel
```

### **Transform Relationships**

#### **Static Transforms (Fixed Relationships)**
```python
# static_transform_publisher configuration
static_transforms = [
    # IMU mounting transform
    {
        'frame_id': 'base_link',
        'child_frame_id': 'imu_link',
        'translation': [0.0, 0.0, 0.1],  # meters
        'rotation': [0.0, 0.0, 0.0, 1.0]  # quaternion (w,x,y,z)
    },
    # LIDAR mounting transform
    {
        'frame_id': 'base_link',
        'child_frame_id': 'lidar_link',
        'translation': [0.2, 0.0, 0.3],
        'rotation': [0.0, 0.0, 0.0, 1.0]
    },
    # Camera mounting transform
    {
        'frame_id': 'base_link',
        'child_frame_id': 'camera_link',
        'translation': [0.33, -0.096, 0.82],
        'rotation': [0.0, 0.707, 0.0, 0.707]  # 90Â° rotation around Y
    }
]
```

#### **Dynamic Transforms (Moving Relationships)**
```python
# Odometry transform (base_link -> odom)
def publish_odometry_transform(self, linear_velocity, angular_velocity, dt):
    """Publish odometry transform based on wheel encoders/IMU"""

    # Integrate velocity to get position/orientation
    self.x += linear_velocity * dt * cos(self.yaw)
    self.y += linear_velocity * dt * sin(self.yaw)
    self.yaw += angular_velocity * dt

    # Create transform
    transform = TransformStamped()
    transform.header.stamp = self.get_clock().now().to_msg()
    transform.header.frame_id = 'odom'
    transform.child_frame_id = 'base_link'

    transform.transform.translation.x = self.x
    transform.transform.translation.y = self.y
    transform.transform.translation.z = 0.0

    # Convert yaw to quaternion
    transform.transform.rotation = self.yaw_to_quaternion(self.yaw)

    self.tf_broadcaster.sendTransform(transform)
```

---

## ðŸš€ **TF Tree Implementation**

### **Phase 1: Static Transform Publishers**

#### **Launch File Configuration**
```python
# tf_static_launch.py
from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        # IMU static transform
        Node(
            package='tf2_ros',
            executable='static_transform_publisher',
            name='imu_broadcaster',
            arguments=['0', '0', '0.1', '0', '0', '0', 'base_link', 'imu_link']
        ),

        # LIDAR static transform
        Node(
            package='tf2_ros',
            executable='static_transform_publisher',
            name='lidar_broadcaster',
            arguments=['0.2', '0', '0.3', '0', '0', '0', 'base_link', 'lidar_link']
        ),

        # Camera static transform
        Node(
            package='tf2_ros',
            executable='static_transform_publisher',
            name='camera_broadcaster',
            arguments=['0.33', '-0.096', '0.82', '0', '0.707', '0', '0.707', 'base_link', 'camera_link']
        ),

        # GPS static transform
        Node(
            package='tf2_ros',
            executable='static_transform_publisher',
            name='gps_broadcaster',
            arguments=['0.093', '0', '0.657', '0', '0', '0', 'base_link', 'gps_link']
        )
    ])
```

#### **URDF-Based Static Transforms**
```xml
<!-- robot_tf.urdf.xacro -->
<?xml version="1.0"?>
<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="rover_tf">

  <!-- Base link definition -->
  <link name="base_link"/>

  <!-- IMU link and transform -->
  <link name="imu_link"/>
  <joint name="imu_joint" type="fixed">
    <parent link="base_link"/>
    <child link="imu_link"/>
    <origin xyz="0 0 0.1" rpy="0 0 0"/>
  </joint>

  <!-- LIDAR link and transform -->
  <link name="lidar_link"/>
  <joint name="lidar_joint" type="fixed">
    <parent link="base_link"/>
    <child link="lidar_link"/>
    <origin xyz="0.2 0 0.3" rpy="0 0 0"/>
  </joint>

  <!-- Camera link and transform -->
  <link name="camera_link"/>
  <joint name="camera_joint" type="fixed">
    <parent link="base_link"/>
    <child link="camera_link"/>
    <origin xyz="0.33 -0.096 0.82" rpy="0 1.571 0"/>
  </joint>

</robot>
```

### **Phase 2: Dynamic Transform Publishers**

#### **Odometry Publisher**
```python
# odometry_tf_publisher.py
import rclpy
from rclpy.node import Node
from nav_msgs.msg import Odometry
from tf2_ros import TransformBroadcaster
from geometry_msgs.msg import TransformStamped
import math

class OdometryTFPublisher(Node):
    def __init__(self):
        super().__init__('odometry_tf_publisher')

        # TF broadcaster
        self.tf_broadcaster = TransformBroadcaster(self)

        # Odometry subscriber
        self.subscription = self.create_subscription(
            Odometry,
            'odom',
            self.odom_callback,
            10
        )

        # Store previous transform for velocity calculation
        self.prev_transform = None
        self.prev_time = None

    def odom_callback(self, msg):
        """Convert odometry message to TF transform"""

        # Create transform message
        transform = TransformStamped()

        transform.header.stamp = msg.header.stamp
        transform.header.frame_id = 'odom'
        transform.child_frame_id = 'base_link'

        # Copy pose
        transform.transform.translation.x = msg.pose.pose.position.x
        transform.transform.translation.y = msg.pose.pose.position.y
        transform.transform.translation.z = msg.pose.pose.position.z

        transform.transform.rotation = msg.pose.pose.orientation

        # Publish transform
        self.tf_broadcaster.sendTransform(transform)
```

#### **Wheel Odometry Publisher**
```python
# wheel_odometry_tf.py
class WheelOdometryTFPublisher(Node):
    def __init__(self):
        super().__init__('wheel_odometry_tf')

        self.tf_broadcaster = TransformBroadcaster(self)

        # Subscribe to wheel encoder topics
        self.front_left_sub = self.create_subscription(
            Float64, '/wheel/front_left/velocity', self.encoder_callback, 10
        )
        self.front_right_sub = self.create_subscription(
            Float64, '/wheel/front_right/velocity', self.encoder_callback, 10
        )
        self.rear_left_sub = self.create_subscription(
            Float64, '/wheel/rear_left/velocity', self.encoder_callback, 10
        )
        self.rear_right_sub = self.create_subscription(
            Float64, '/wheel/rear_right/velocity', self.encoder_callback, 10
        )

        # Odometry state
        self.x = 0.0
        self.y = 0.0
        self.yaw = 0.0

        # Wheel parameters
        self.wheel_radius = 0.165  # meters
        self.wheel_base = 0.77     # meters (width)
        self.track_width = 1.015   # meters (length)

        self.last_time = self.get_clock().now()

    def encoder_callback(self, msg, wheel_name):
        """Process wheel encoder data"""

        current_time = self.get_clock().now()
        dt = (current_time - self.last_time).nanoseconds / 1e9

        # Calculate linear and angular velocity
        wheel_velocity = msg.data  # rad/s
        linear_velocity = wheel_velocity * self.wheel_radius

        # Differential drive kinematics (simplified)
        angular_velocity = (linear_velocity / self.wheel_base) * (
            self.right_velocity - self.left_velocity
        ) / 2.0

        # Integrate odometry
        self.x += linear_velocity * dt * math.cos(self.yaw)
        self.y += linear_velocity * dt * math.sin(self.yaw)
        self.yaw += angular_velocity * dt

        # Publish TF
        self.publish_tf(current_time)
        self.last_time = current_time

    def publish_tf(self, timestamp):
        """Publish odometry transform"""

        transform = TransformStamped()
        transform.header.stamp = timestamp.to_msg()
        transform.header.frame_id = 'odom'
        transform.child_frame_id = 'base_link'

        transform.transform.translation.x = self.x
        transform.transform.translation.y = self.y
        transform.transform.translation.z = 0.0

        # Convert yaw to quaternion
        transform.transform.rotation.w = math.cos(self.yaw / 2.0)
        transform.transform.rotation.x = 0.0
        transform.transform.rotation.y = 0.0
        transform.transform.rotation.z = math.sin(self.yaw / 2.0)

        self.tf_broadcaster.sendTransform(transform)
```

### **Phase 3: Robotic Arm TF Publisher**

#### **Joint State TF Publisher**
```python
# arm_tf_publisher.py
class ArmTFPublisher(Node):
    def __init__(self):
        super().__init__('arm_tf_publisher')

        self.tf_broadcaster = TransformBroadcaster(self)

        # Subscribe to joint states
        self.joint_sub = self.create_subscription(
            JointState, '/joint_states', self.joint_callback, 10
        )

        # Arm kinematic chain definition
        self.joint_names = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']
        self.link_names = ['arm_base', 'arm_link1', 'arm_link2', 'arm_link3',
                          'arm_link4', 'arm_link5', 'arm_end_effector']

        # DH parameters (Denavit-Hartenberg)
        self.dh_params = [
            {'a': 0, 'alpha': math.pi/2, 'd': 0.1, 'theta': 0},  # joint1
            {'a': 0.3, 'alpha': 0, 'd': 0, 'theta': 0},          # joint2
            {'a': 0.25, 'alpha': 0, 'd': 0, 'theta': 0},         # joint3
            {'a': 0, 'alpha': math.pi/2, 'd': 0.2, 'theta': 0},  # joint4
            {'a': 0, 'alpha': -math.pi/2, 'd': 0, 'theta': 0},   # joint5
            {'a': 0, 'alpha': 0, 'd': 0.1, 'theta': 0}           # joint6
        ]

    def joint_callback(self, msg):
        """Publish TF transforms for all arm joints"""

        # Extract joint positions
        joint_positions = {}
        for i, name in enumerate(msg.name):
            if name in self.joint_names:
                joint_positions[name] = msg.position[i]

        # Publish transforms for each link
        parent_frame = 'arm_base_link'

        for i, (joint_name, link_name) in enumerate(zip(self.joint_names, self.link_names[1:])):
            if joint_name in joint_positions:
                transform = self.compute_fk_transform(
                    parent_frame, link_name, self.dh_params[i],
                    joint_positions[joint_name]
                )
                self.tf_broadcaster.sendTransform(transform)
                parent_frame = link_name

    def compute_fk_transform(self, parent_frame, child_frame, dh_param, joint_angle):
        """Compute forward kinematics transform using DH parameters"""

        a = dh_param['a']
        alpha = dh_param['alpha']
        d = dh_param['d']
        theta = dh_param['theta'] + joint_angle

        # DH transformation matrix
        ct = math.cos(theta)
        st = math.sin(theta)
        ca = math.cos(alpha)
        sa = math.sin(alpha)

        transform_matrix = [
            [ct, -st*ca, st*sa, a*ct],
            [st, ct*ca, -ct*sa, a*st],
            [0, sa, ca, d],
            [0, 0, 0, 1]
        ]

        # Convert to TransformStamped
        transform = TransformStamped()
        transform.header.stamp = self.get_clock().now().to_msg()
        transform.header.frame_id = parent_frame
        transform.child_frame_id = child_frame

        # Extract translation
        transform.transform.translation.x = transform_matrix[0][3]
        transform.transform.translation.y = transform_matrix[1][3]
        transform.transform.translation.z = transform_matrix[2][3]

        # Convert rotation matrix to quaternion
        # (Simplified - use proper quaternion conversion)
        transform.transform.rotation = self.matrix_to_quaternion(transform_matrix)

        return transform
```

---

## ðŸ” **TF Tree Debugging & Validation**

### **TF Tree Visualization**
```bash
# View current TF tree
ros2 run tf2_tools view_frames.py
ros2 run tf2_tools view_frames.py --output tf_tree.pdf  # Generate PDF

# Launch RViz for interactive visualization
ros2 launch urc_bringup rviz.launch.py
```

### **TF Monitoring Tools**
```python
# tf_monitor.py
class TFMonitor(Node):
    def __init__(self):
        super().__init__('tf_monitor')

        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # Monitor critical transforms
        self.critical_transforms = [
            ('map', 'base_link'),
            ('odom', 'base_link'),
            ('base_link', 'camera_link'),
            ('base_link', 'imu_link'),
            ('base_link', 'lidar_link')
        ]

        self.timer = self.create_timer(1.0, self.check_transforms)

    def check_transforms(self):
        """Check availability and freshness of critical transforms"""

        for parent, child in self.critical_transforms:
            try:
                transform = self.tf_buffer.lookup_transform(
                    parent, child, rclpy.time.Time()
                )

                # Check transform age
                age = self.get_clock().now() - rclpy.time.Time.from_msg(transform.header.stamp)
                age_seconds = age.nanoseconds / 1e9

                if age_seconds > 1.0:  # More than 1 second old
                    self.get_logger().warn(
                        f'Transform {parent} -> {child} is {age_seconds:.2f}s old'
                    )

            except TransformException as e:
                self.get_logger().error(
                    f'Failed to lookup transform {parent} -> {child}: {str(e)}'
                )
```

### **TF Echo Tool**
```bash
# Check specific transform
ros2 run tf2_ros tf2_echo map base_link

# Monitor transform over time
ros2 run tf2_ros tf2_monitor map base_link

# Check transform tree structure
ros2 run tf2_tools view_frames
```

### **Common TF Issues & Solutions**

#### **1. Transform Timeout Errors**
```
Error: "Lookup would require extrapolation into the future"
```
**Cause**: Transform publisher delay or timestamp issues
**Solution**:
```python
# Use appropriate timestamp
transform.header.stamp = self.get_clock().now().to_msg()

# Or use latest available transform
transform = self.tf_buffer.lookup_transform(
    target_frame, source_frame, rclpy.time.Time()
)
```

#### **2. Extrapolation Errors**
```
Error: "Lookup would require extrapolation X seconds into the past"
```
**Cause**: Transform buffer doesn't have data for requested timestamp
**Solution**:
```python
# Use latest available transform instead of specific timestamp
try:
    transform = self.tf_buffer.lookup_transform(
        target_frame, source_frame, rclpy.time.Time()  # Latest
    )
except TransformException:
    # Handle missing transform
    pass
```

#### **3. Multiple Publishers**
```
Warning: "TF_OLD_DATA: TF_OLD_DATA ignoring data from the past"
```
**Cause**: Multiple nodes publishing same transform
**Solution**: Ensure only one publisher per transform pair

#### **4. Coordinate Frame Mismatches**
```
Error: "Frame not found" or incorrect transformations
```
**Cause**: Frame ID typos or missing publishers
**Solution**:
```bash
# List all available frames
ros2 run tf2_tools view_frames

# Check frame connections
ros2 run tf2_tools view_frames --output frames.pdf
```

---

## ðŸ“Š **TF Performance Optimization**

### **Publishing Frequency Guidelines**
- **Static transforms**: Publish once at startup
- **Odometry**: 30-100 Hz
- **Sensor transforms**: Match sensor data rate
- **Joint transforms**: Match joint state publishing rate

### **Buffer Management**
```python
# Configure TF buffer for better performance
self.tf_buffer = Buffer(cache_time=rclpy.duration.Duration(seconds=30))
self.tf_listener = TransformListener(self.tf_buffer, self)

# Clear old data periodically
if len(self.tf_buffer._buffer) > 1000:
    # Implement buffer cleanup if needed
    pass
```

### **Transform Caching**
```python
class CachedTFListener:
    def __init__(self):
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # Cache frequently used transforms
        self.cached_transforms = {}
        self.cache_timeout = rclpy.duration.Duration(seconds=0.1)

    def get_cached_transform(self, target_frame, source_frame):
        """Get transform with caching"""

        cache_key = f"{target_frame}_{source_frame}"
        current_time = self.get_clock().now()

        # Check if cached transform is still valid
        if (cache_key in self.cached_transforms and
            current_time - self.cached_transforms[cache_key]['timestamp'] < self.cache_timeout):

            return self.cached_transforms[cache_key]['transform']

        # Lookup new transform
        try:
            transform = self.tf_buffer.lookup_transform(
                target_frame, source_frame, rclpy.time.Time()
            )

            # Cache it
            self.cached_transforms[cache_key] = {
                'transform': transform,
                'timestamp': current_time
            }

            return transform

        except TransformException:
            return None
```

---

## ðŸ”— **Integration with Navigation Stack**

### **EKF Integration**
```yaml
# ekf_config.yaml - TF integration
ekf_filter_node:
  ros__parameters:
    # Transform time tolerance
    transform_time_offset: 0.0
    transform_timeout: 0.1

    # World frame (map -> odom)
    world_frame: odom

    # Base link frame
    base_link_frame: base_link

    # Sensor frames
    odom_frame: odom
    map_frame: map

    # IMU frame
    imu0: imu/data
    imu0_config: [false, false, false,
                  true,  true,  true,
                  false, false, false,
                  true,  true,  true,
                  true,  true,  true]
    imu0_frame: imu_link

    # GPS frame
    navsat0: gps/fix
    navsat0_config: [true, true, true,
                     false, false, false,
                     false, false, false,
                     false, false, false,
                     false, false, false]
    navsat0_frame: gps_link
```

### **SLAM Integration**
```yaml
# slam_config.yaml - TF setup
slam_toolbox:
  ros__parameters:
    # Transform configuration
    odom_frame: odom
    map_frame: map
    base_frame: base_link

    # Sensor transforms
    scan_topic: /scan
    scan_frame: lidar_link

    # Camera transforms (for visual odometry)
    image_topic: /camera/color/image_raw
    camera_frame: camera_link
```

---

## ðŸ“ˆ **TF Tree Validation & Testing**

### **Automated TF Tests**
```python
# test_tf_tree.py
class TFTreeTest(Node):
    def __init__(self):
        super().__init__('tf_tree_test')

        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # Test transforms
        self.test_transforms = [
            ('map', 'base_link'),
            ('odom', 'base_link'),
            ('base_link', 'camera_link'),
            ('base_link', 'imu_link'),
            ('base_link', 'lidar_link'),
            ('base_link', 'arm_end_effector')
        ]

        self.timer = self.create_timer(5.0, self.run_tf_tests)

    def run_tf_tests(self):
        """Run comprehensive TF tree validation"""

        success_count = 0

        for parent, child in self.test_transforms:
            try:
                # Test transform lookup
                transform = self.tf_buffer.lookup_transform(
                    parent, child, rclpy.time.Time()
                )

                # Check transform validity
                translation = transform.transform.translation
                rotation = transform.transform.rotation

                # Validate quaternion
                quat_norm = math.sqrt(rotation.w**2 + rotation.x**2 +
                                    rotation.y**2 + rotation.z**2)

                if abs(quat_norm - 1.0) > 0.1:
                    self.get_logger().error(f'Invalid quaternion for {parent}->{child}')
                    continue

                # Check for NaN values
                if (math.isnan(translation.x) or math.isnan(translation.y) or
                    math.isnan(translation.z)):
                    self.get_logger().error(f'NaN values in translation for {parent}->{child}')
                    continue

                success_count += 1
                self.get_logger().info(f'âœ“ Transform {parent}->{child} OK')

            except TransformException as e:
                self.get_logger().error(f'âœ— Transform {parent}->{child} failed: {str(e)}')

        # Summary
        total_tests = len(self.test_transforms)
        success_rate = success_count / total_tests * 100

        if success_rate >= 90.0:
            self.get_logger().info(f'TF Tree Status: HEALTHY ({success_count}/{total_tests} transforms OK)')
        else:
            self.get_logger().error(f'TF Tree Status: DEGRADED ({success_count}/{total_tests} transforms OK)')
```

### **Performance Benchmarks**
```python
# benchmark_tf_performance.py
class TFPerformanceBenchmark(Node):
    def __init__(self):
        super().__init__('tf_performance_benchmark')

        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        self.lookup_times = []
        self.timer = self.create_timer(0.1, self.benchmark_lookup)

    def benchmark_lookup(self):
        """Benchmark TF lookup performance"""

        start_time = time.time()

        try:
            transform = self.tf_buffer.lookup_transform(
                'map', 'base_link', rclpy.time.Time()
            )
            lookup_time = time.time() - start_time
            self.lookup_times.append(lookup_time)

            # Keep only recent samples
            if len(self.lookup_times) > 100:
                self.lookup_times.pop(0)

            # Calculate statistics
            if len(self.lookup_times) >= 10:
                avg_time = sum(self.lookup_times) / len(self.lookup_times)
                max_time = max(self.lookup_times)

                if avg_time > 0.01:  # More than 10ms average
                    self.get_logger().warn('.4f')
                if max_time > 0.1:  # More than 100ms worst case
                    self.get_logger().error('.4f')

        except TransformException:
            pass
```

---

## âœ… **TF Tree Setup Checklist**

### **Static Transforms**
- [ ] All sensor mounting positions measured accurately
- [ ] URDF includes all fixed joint transforms
- [ ] Static transform publishers configured
- [ ] Transform validity verified

### **Dynamic Transforms**
- [ ] Odometry publisher implemented
- [ ] Wheel encoder TF integration complete
- [ ] Robotic arm joint TF publishing working
- [ ] Transform timestamps synchronized

### **Integration & Testing**
- [ ] Navigation stack receives correct transforms
- [ ] SLAM system uses proper sensor frames
- [ ] Computer vision transforms camera coordinates
- [ ] Autonomous typing uses accurate arm transforms

### **Monitoring & Maintenance**
- [ ] TF monitoring tools deployed
- [ ] Performance benchmarks established
- [ ] Automated tests integrated into CI/CD
- [ ] Documentation updated with transform relationships

### **Performance Validation**
- [ ] Transform lookup latency <10ms average
- [ ] No transform extrapolation errors
- [ ] Coordinate frame consistency verified
- [ ] Mission-critical transforms always available

---

**ðŸŽ¯ Success Criteria**: TF tree setup complete when all coordinate transformations are accurate (<1cm, <1Â° error), transforms publish at appropriate frequencies, and sensor fusion operates without frame-related errors, enabling reliable autonomous navigation and manipulation for URC 2026 mission success.
