#!/usr/bin/env python3
"""
ğŸš€ Velocity Acceleration Tools

Scripts to maintain development velocity and prevent backtracking.
"""

import os
import json
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any

class VelocityMonitor:
    """Monitor development velocity and identify slowdowns."""

    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)

    def get_velocity_metrics(self, days: int = 7) -> Dict[str, Any]:
        """Calculate velocity metrics for the last N days."""
        try:
            # Get git stats
            since_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

            # Commit count
            commit_result = subprocess.run(
                ["git", "rev-list", "--count", f"--since={since_date}", "HEAD"],
                capture_output=True, text=True, cwd=self.repo_path
            )
            commit_count = int(commit_result.stdout.strip()) if commit_result.returncode == 0 else 0

            # Lines changed
            lines_result = subprocess.run(
                ["git", "log", f"--since={since_date}", "--pretty=tformat:", "--numstat"],
                capture_output=True, text=True, cwd=self.repo_path
            )
            lines_changed = 0
            if lines_result.returncode == 0:
                for line in lines_result.stdout.split('\n'):
                    if line.strip() and '\t' in line:
                        parts = line.split('\t')
                        if len(parts) >= 2:
                            try:
                                lines_changed += int(parts[0]) + int(parts[1])
                            except ValueError:
                                pass

            # File changes
            files_result = subprocess.run(
                ["git", "log", f"--since={since_date}", "--pretty=tformat:", "--name-only"],
                capture_output=True, text=True, cwd=self.repo_path
            )
            files_changed = set()
            if files_result.returncode == 0:
                for line in files_result.stdout.split('\n'):
                    if line.strip() and not line.startswith(' '):
                        files_changed.add(line.strip())

            return {
                'period_days': days,
                'commits': commit_count,
                'lines_changed': lines_changed,
                'files_changed': len(files_changed),
                'commits_per_day': commit_count / days,
                'lines_per_commit': lines_changed / commit_count if commit_count > 0 else 0,
                'velocity_score': self._calculate_velocity_score(commit_count, lines_changed, len(files_changed), days)
            }

        except Exception as e:
            return {
                'error': str(e),
                'period_days': days,
                'commits': 0,
                'velocity_score': 0
            }

    def _calculate_velocity_score(self, commits: int, lines: int, files: int, days: int) -> float:
        """Calculate velocity score (0-100)."""
        # Base score from commits (ideal: 3-5 per day)
        commit_score = min(commits / (days * 3), 1.0) * 40

        # Productivity score from lines changed (ideal: 100-500 per day)
        productivity_score = min(lines / (days * 200), 1.0) * 30

        # Breadth score from files changed (ideal: 5-15 per day)
        breadth_score = min(files / (days * 5), 1.0) * 30

        return commit_score + productivity_score + breadth_score

    def identify_blockers(self) -> List[str]:
        """Identify potential development blockers."""
        blockers = []

        # Check for failing CI/CD
        if self._check_recent_ci_failures():
            blockers.append("ğŸš¨ Recent CI/CD failures detected")

        # Check for merge conflicts
        if self._check_merge_conflicts():
            blockers.append("âš ï¸ Merge conflicts in recent commits")

        # Check for uncommitted changes
        if self._check_uncommitted_changes():
            blockers.append("ğŸ“ Uncommitted changes may indicate WIP blockers")

        # Check for outdated branches
        if self._check_outdated_branches():
            blockers.append("ğŸŒ¿ Outdated branches may cause integration issues")

        return blockers

    def _check_recent_ci_failures(self) -> bool:
        """Check for recent CI/CD failures."""
        # This would integrate with GitHub API in real implementation
        return False  # Placeholder

    def _check_merge_conflicts(self) -> bool:
        """Check for recent merge conflicts."""
        try:
            result = subprocess.run(
                ["git", "log", "--oneline", "--grep=Merge conflict", "-n", "5"],
                capture_output=True, text=True, cwd=self.repo_path
            )
            return len(result.stdout.strip().split('\n')) > 1
        except:
            return False

    def _check_uncommitted_changes(self) -> bool:
        """Check for uncommitted changes."""
        try:
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True, text=True, cwd=self.repo_path
            )
            return len(result.stdout.strip()) > 0
        except:
            return False

    def _check_outdated_branches(self) -> bool:
        """Check for outdated branches."""
        try:
            # Get branches that haven't been updated in 7+ days
            result = subprocess.run(
                ["git", "branch", "--format=%(refname:short)|%(committerdate:relative)"],
                capture_output=True, text=True, cwd=self.repo_path
            )

            outdated = []
            for line in result.stdout.split('\n'):
                if '|' in line:
                    branch, date = line.split('|', 1)
                    if any(word in date for word in ['week', 'month', 'year']):
                        outdated.append(branch.strip())

            return len(outdated) > 2  # More than 2 outdated branches is concerning
        except:
            return False

class ArchitectureSimplifier:
    """Tools to simplify and maintain clean architecture."""

    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)

    def generate_interfaces(self) -> Dict[str, Any]:
        """Generate interface definitions for subsystems."""
        return {
            'state_management': {
                'topics': {
                    'mission_status': 'MissionState',
                    'subsystem_health': 'HealthStatus'
                },
                'services': {
                    'get_mission': 'GetMission',
                    'abort_mission': 'AbortMission'
                },
                'actions': {
                    'execute_mission': 'ExecuteMission'
                }
            },
            'navigation': {
                'topics': {
                    'goal': 'PoseStamped',
                    'status': 'NavigationStatus'
                },
                'services': {
                    'navigate_to': 'NavigateTo'
                }
            },
            'slam': {
                'topics': {
                    'pose': 'PoseWithCovarianceStamped',
                    'map': 'OccupancyGrid'
                }
            },
            'computer_vision': {
                'topics': {
                    'detections': 'DetectionArray',
                    'aruco_poses': 'PoseArray'
                }
            }
        }

    def validate_architecture(self) -> Dict[str, Any]:
        """Validate architecture cleanliness."""
        issues = []

        # Check for circular dependencies
        if self._has_circular_dependencies():
            issues.append("âš ï¸ Potential circular dependencies detected")

        # Check interface consistency
        interface_issues = self._check_interface_consistency()
        issues.extend(interface_issues)

        # Check for unused imports
        import_issues = self._check_unused_imports()
        issues.extend(import_issues)

        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'recommendations': self._generate_recommendations(issues)
        }

    def _has_circular_dependencies(self) -> bool:
        """Check for circular import dependencies."""
        # Simplified check - look for suspicious import patterns
        python_files = list(self.repo_path.glob("Autonomy/code/*/*.py"))

        imports = {}
        for file in python_files:
            try:
                with open(file, 'r') as f:
                    content = f.read()
                    # Extract imports
                    import_lines = [line for line in content.split('\n')
                                  if line.strip().startswith(('import', 'from'))]
                    imports[str(file)] = import_lines
            except:
                pass

        # Basic circular dependency check (simplified)
        return False  # Would need more sophisticated analysis

    def _check_interface_consistency(self) -> List[str]:
        """Check interface consistency across subsystems."""
        issues = []
        # This would analyze topic/service definitions for consistency
        return issues

    def _check_unused_imports(self) -> List[str]:
        """Check for unused imports."""
        issues = []
        # This would run a code analysis tool
        return issues

    def _generate_recommendations(self, issues: List[str]) -> List[str]:
        """Generate recommendations based on issues."""
        recommendations = []

        if any('circular' in issue.lower() for issue in issues):
            recommendations.append("ğŸ”„ Refactor to eliminate circular dependencies")

        if any('interface' in issue.lower() for issue in issues):
            recommendations.append("ğŸ”— Standardize topic/service naming conventions")

        if any('import' in issue.lower() for issue in issues):
            recommendations.append("ğŸ§¹ Remove unused imports to reduce complexity")

        if not recommendations:
            recommendations.append("âœ… Architecture looks clean - maintain current practices")

        return recommendations

class RiskMitigator:
    """Tools to identify and mitigate development risks."""

    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)

    def assess_risks(self) -> Dict[str, Any]:
        """Assess current development risks."""
        risks = {
            'high': [],
            'medium': [],
            'low': []
        }

        # Timeline risk
        days_remaining = 40  # Would be calculated dynamically
        if days_remaining < 20:
            risks['high'].append("â° Critical timeline pressure")

        # Technical debt risk
        if self._has_high_technical_debt():
            risks['medium'].append("ğŸ’¸ Accumulating technical debt")

        # Integration risk
        if self._has_integration_issues():
            risks['high'].append("ğŸ”— Integration complexity")

        # Team risk
        if self._has_team_issues():
            risks['medium'].append("ğŸ‘¥ Team coordination challenges")

        return {
            'overall_risk_level': self._calculate_risk_level(risks),
            'risks': risks,
            'mitigations': self._generate_mitigations(risks)
        }

    def _has_high_technical_debt(self) -> bool:
        """Check for high technical debt indicators."""
        # Check for TODO comments, large files, etc.
        todo_count = 0
        large_files = 0

        for py_file in self.repo_path.glob("Autonomy/code/**/*.py"):
            try:
                with open(py_file, 'r') as f:
                    content = f.read()

                # Count TODOs
                todo_count += content.upper().count('TODO')

                # Check file size
                if len(content) > 1000:  # Arbitrary threshold
                    large_files += 1

            except:
                pass

        return todo_count > 20 or large_files > 5

    def _has_integration_issues(self) -> bool:
        """Check for integration issues."""
        # This would check CI/CD results, merge conflicts, etc.
        return False  # Placeholder

    def _has_team_issues(self) -> bool:
        """Check for team coordination issues."""
        # This would analyze commit patterns, etc.
        return False  # Placeholder

    def _calculate_risk_level(self, risks: Dict[str, List]) -> str:
        """Calculate overall risk level."""
        high_count = len(risks['high'])
        medium_count = len(risks['medium'])

        if high_count > 0:
            return 'HIGH'
        elif medium_count > 2:
            return 'MEDIUM'
        else:
            return 'LOW'

    def _generate_mitigations(self, risks: Dict[str, List]) -> List[str]:
        """Generate risk mitigation strategies."""
        mitigations = []

        for risk in risks['high'] + risks['medium']:
            if 'timeline' in risk.lower():
                mitigations.append("ğŸ“… Implement daily progress checkpoints")
                mitigations.append("ğŸ¯ Prioritize MVP features only")
            elif 'technical debt' in risk.lower():
                mitigations.append("ğŸ§¹ Schedule weekly code cleanup sessions")
                mitigations.append("ğŸ“ Convert TODOs to issues immediately")
            elif 'integration' in risk.lower():
                mitigations.append("ğŸ”— Establish daily integration testing")
                mitigations.append("ğŸ“‹ Define clear interface contracts")
            elif 'team' in risk.lower():
                mitigations.append("ğŸ‘¥ Increase communication frequency")
                mitigations.append("ğŸ“Š Implement pair programming for complex features")

        return mitigations

def main():
    """Main velocity monitoring and risk assessment."""
    monitor = VelocityMonitor()
    simplifier = ArchitectureSimplifier()
    mitigator = RiskMitigator()

    # Get velocity metrics
    velocity = monitor.get_velocity_metrics(days=7)
    print("ğŸš€ VELOCITY METRICS (Last 7 days):")
    print(json.dumps(velocity, indent=2))

    # Check for blockers
    blockers = monitor.identify_blockers()
    if blockers:
        print("\nğŸš¨ POTENTIAL BLOCKERS:")
        for blocker in blockers:
            print(f"  {blocker}")

    # Architecture validation
    arch_validation = simplifier.validate_architecture()
    print(f"\nğŸ—ï¸ ARCHITECTURE STATUS: {'âœ… VALID' if arch_validation['valid'] else 'âš ï¸ ISSUES'}")
    if not arch_validation['valid']:
        print("Issues:")
        for issue in arch_validation['issues']:
            print(f"  {issue}")

    # Risk assessment
    risks = mitigator.assess_risks()
    print(f"\nğŸ›¡ï¸ RISK LEVEL: {risks['overall_risk_level']}")
    if risks['mitigations']:
        print("Recommended Mitigations:")
        for mitigation in risks['mitigations']:
            print(f"  {mitigation}")

if __name__ == '__main__':
    main()
